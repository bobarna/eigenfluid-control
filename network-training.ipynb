{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phi.torch.flow import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.eigenfluid import Eigenfluid\n",
    "from src.shapes import *\n",
    "\n",
    "# Helper functions for visualization\n",
    "from src.visu import *\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acffcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of basis fields\n",
    "N = 4**2 \n",
    "# Domain sizes\n",
    "DOMAIN = Box(x=math.PI, y=math.PI)\n",
    "# NOT for sampling points, but for reconstructing the velocity grid\n",
    "SAMPLING_SIZE = 32\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "VISU_NR = 5\n",
    "\n",
    "start_time = time.time()\n",
    "eigenfluid = Eigenfluid(N, DOMAIN, SAMPLING_SIZE, init_w='zero')\n",
    "end_time = time.time()\n",
    "print(\"Eigenfluid initialized in {} seconds\".format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779bb2b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ba06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get O overlapping, and U non-necessarily overlapping ('unique') sample points\n",
    "O = 30\n",
    "U = 30\n",
    "N_S = O+U\n",
    "\n",
    "def get_points_for_shapes(shape_0, shape_target):\n",
    "    sampler_union = ShapeSampler(shape_0, shape_target, N=O, h1=2, h2=7)\n",
    "    sampler_0 = ShapeSampler(shape_0, N=U, h1=3, h2=11)\n",
    "    sampler_target = ShapeSampler(shape_target, N=U, h1=3, h2=11)\n",
    "    # Concatenate both the union and non-union points\n",
    "    p_0 = math.concat((sampler_union.p, sampler_0.p), instance('i'))\n",
    "    p_0 = shape_0.create_points(p_0)\n",
    "    p_t = math.concat((sampler_union.p, sampler_target.p), instance('i'))\n",
    "    p_t = shape_target.create_points(p_t)\n",
    "    \n",
    "    return (p_0, p_t)\n",
    "\n",
    "p_0_list = []\n",
    "p_t_list = []\n",
    "for i in range(BATCH_SIZE):\n",
    "    # Circle / Square / Triangle\n",
    "    Shape_0 = [Circle, Square, Triangle][np.random.randint(3)]\n",
    "    Shape_target = [Circle, Square, Triangle][np.random.randint(3)]\n",
    "    # Random positions [0,2] x [0,2]\n",
    "    shape_0 = Shape_0(pos=(np.random.rand()*2, np.random.rand()*2))\n",
    "    shape_target = Shape_target(pos=(np.random.rand()*2, np.random.rand()*2))\n",
    "    \n",
    "    p_0, p_t = get_points_for_shapes(shape_0, shape_target)\n",
    "    p_0_list.append(p_0)\n",
    "    p_t_list.append(p_t)\n",
    "\n",
    "    \n",
    "p_0 = math.stack(p_0_list, batch(batch=BATCH_SIZE))\n",
    "p_t = math.stack(p_t_list, batch(batch=BATCH_SIZE))\n",
    "\n",
    "# Generate transition data\n",
    "STEPS = 16 #p_0 is at time step 1\n",
    "p_trajectory = math.tensor([p_0+(p_t - p_0)/STEPS*t for t in range(STEPS)], batch('time') & p_0.shape)\n",
    "\n",
    "plot({\n",
    "    \"Blue: start shape\\nRed: target shape\\nGreen: Linear Trajectory\": vis.overlay(\n",
    "        PointCloud(p_0.batch[:VISU_NR], bounds=DOMAIN),\n",
    "        PointCloud(p_t.batch[:VISU_NR], bounds=DOMAIN, color=\"red\"),\n",
    "        PointCloud(p_trajectory.batch[:VISU_NR], bounds=DOMAIN, color=\"green\"),\n",
    "     )}, \n",
    "     animate='time',\n",
    "     size=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3873d79",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = 16 # Already defined during data generation\n",
    "DT    = 0.2\n",
    "VISCOSITY = 0.0\n",
    "\n",
    "def to_model(p_0, p_t, w):\n",
    "    return math.stack([\n",
    "        p_0['x'], p_0['y'],\n",
    "        p_t['x'], p_t['y'],\n",
    "        math.pad(math.rename_dims(w, 'k', instance('i')), {'i': (0,N_S-N)}, extrapolation.ZERO)\n",
    "    ], channel('channels'))\n",
    "\n",
    "# Get the 4th channel, and reshape it to match the dimensions of w (=> instance('k'))\n",
    "def from_model(net_output):\n",
    "    return math.rename_dims(tensor(\n",
    "        net_output,\n",
    "        batch('batch') & channel(channels=5) & channel('vector')\n",
    "    ).channels[4], 'vector', instance('k'))\n",
    "\n",
    "@math.jit_compile\n",
    "def loss_function(p_0, p_t, w):\n",
    "    loss = 0\n",
    "    p_est = p_0.time[0]\n",
    "    p_est_traj = [p_est]\n",
    "    for t in range(STEPS-1):\n",
    "        # Feed data into NN to get CFE prediction\n",
    "        model_input = to_model(p_est, p_t.time[t], w)\n",
    "        model_output = net(model_input.native('batch,channels,i'))\n",
    "        f_pred = from_model(model_output)\n",
    "        #print(\"t={}, f_pred={}\".format(t, f_pred))\n",
    "        w += f_pred\n",
    "        # Step simulation\n",
    "        w = eigenfluid.step_w_euler(w, DT, viscosity=VISCOSITY)\n",
    "        # Get velocities at p_0\n",
    "        v_phi = eigenfluid.phi_template(w, eigenfluid.N, eigenfluid.basis_fields)\n",
    "        p_velocities = v_phi(p_est)\n",
    "        # Midpoint\n",
    "        p_velocities = v_phi(p_est + p_velocities*DT/2)\n",
    "        # Euler step for points\n",
    "        p_est += p_velocities * DT\n",
    "        p_est_traj.append(p_est)\n",
    "        loss += math.l2_loss(p_est - p_t.time[t])\n",
    "    return loss, p_est_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cf5873",
   "metadata": {},
   "source": [
    "# Network and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75540c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: [p_current, p_target, current_w]\n",
    "# -> Input dimension = [O+U, O+U, N]\n",
    "# Output = [N] force coefficients for current time step\n",
    "#net = dense_net(2*2*(O+U)+N, N, [256, 128, 64, 32], batch_norm=True)\n",
    "net = dense_net(N_S, N, [256, 128, 64, 32])\n",
    "optimizer = adam(net)\n",
    "\n",
    "print(net)\n",
    "print(\"Number of parameters: {}\".format(parameter_count(net)))\n",
    "#print()\n",
    "#print(\"Optimizer:{}\".format(optimizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc2296c",
   "metadata": {},
   "source": [
    "### Visualize Untrained CFE NN (first 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d06f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test the loss function and the NN\n",
    "loss, cfe_traj = loss_function(\n",
    "                    p_trajectory.time[0:STEPS-1].batch[:VISU_NR],\n",
    "                    p_trajectory.time[1:STEPS].batch[:VISU_NR],\n",
    "                    math.stack([eigenfluid.w]*VISU_NR, batch('batch'))\n",
    "                )\n",
    "print(\"Loss = {}\".format(loss))\n",
    "cfe_traj = math.stack(cfe_traj, batch('time'))\n",
    "plot(PointCloud(cfe_traj, bounds=DOMAIN), animate='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9603be89",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eb0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1000):\n",
    "    w_optim = math.stack([eigenfluid.w]*BATCH_SIZE, batch('batch'))\n",
    "    loss, p_est_traj = update_weights(net, optimizer, loss_function, \n",
    "                   p_trajectory.time[0:STEPS-1], \n",
    "                   p_trajectory.time[1:STEPS], \n",
    "                   w_optim)\n",
    "    if epoch%10 == 0 or epoch < 5:\n",
    "        print(\"Optimization step {}, loss: {}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0131f85",
   "metadata": {},
   "source": [
    "## Visualize Results (first 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6635664",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, cfe_traj = loss_function(\n",
    "                    p_trajectory.time[0:STEPS-1].batch[15:15+VISU_NR],\n",
    "                    p_trajectory.time[1:STEPS].batch[15:15+VISU_NR],\n",
    "                    math.stack([eigenfluid.w]*VISU_NR, batch('batch'))\n",
    "                )\n",
    "print(\"Loss = {}\".format(loss))\n",
    "cfe_traj = math.stack(cfe_traj, batch('time'))\n",
    "plot(\n",
    "    vis.overlay(\n",
    "        PointCloud(cfe_traj, bounds=DOMAIN),\n",
    "        PointCloud(p_trajectory.time[STEPS-1].batch[15:15+VISU_NR], bounds=DOMAIN, color='red')\n",
    "    ),\n",
    "    animate='time'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d73198",
   "metadata": {},
   "source": [
    "# Test Generalization of NN on Unseen Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a225e6",
   "metadata": {},
   "source": [
    "## Generate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0748541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 10\n",
    "\n",
    "# Generate test data\n",
    "p_0_test_list = []\n",
    "p_t_test_list = []\n",
    "for i in range(TEST_SIZE):\n",
    "    # Circle / Square / Triangle\n",
    "    Shape_0 = [Circle, Square, Triangle][np.random.randint(3)]\n",
    "    Shape_target = [Circle, Square, Triangle][np.random.randint(3)]\n",
    "    # Random positions [0,2] x [0,2]\n",
    "    shape_0 = Shape_0(pos=(np.random.rand()*2, np.random.rand()*2))\n",
    "    shape_target = Shape_target(pos=(np.random.rand()*2, np.random.rand()*2))\n",
    "    \n",
    "    p_0, p_t = get_points_for_shapes(shape_0, shape_target)\n",
    "    p_0_test_list.append(p_0)\n",
    "    p_t_test_list.append(p_t)\n",
    "\n",
    "    \n",
    "p_0_test = math.stack(p_0_test_list, batch(batch=TEST_SIZE))\n",
    "p_t_test = math.stack(p_t_test_list, batch(batch=TEST_SIZE))\n",
    "\n",
    "# Generate transition data\n",
    "p_test_trajectory = math.tensor([p_0_test+(p_t_test - p_0_test)/STEPS*t for t in range(STEPS)], batch('time') & p_0_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd02b5c",
   "metadata": {},
   "source": [
    "## Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbb8d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, test_traj = loss_function(\n",
    "                    p_test_trajectory.time[0:STEPS-1],\n",
    "                    p_test_trajectory.time[1:STEPS],\n",
    "                    math.stack([eigenfluid.w]*TEST_SIZE, batch('batch'))\n",
    "                )\n",
    "print(\"Loss = {}\".format(loss))\n",
    "test_traj = math.stack(test_traj, batch('time'))\n",
    "plot(\n",
    "    vis.overlay(\n",
    "        PointCloud(test_traj.batch[:VISU_NR], bounds=DOMAIN),\n",
    "        PointCloud(p_t_test.batch[:VISU_NR], bounds=DOMAIN, color=\"red\"),\n",
    "    ),\n",
    "    animate='time'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
